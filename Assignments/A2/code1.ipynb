{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 style=\"text-align: center;\">INLP - Assignment 2</h1>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <p>Name: Vedant Nipane</p>\n",
    "    <p>Roll No: 2021102040</p>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "text1_path = 'Pride and Prejudice - Jane Austen.txt'\n",
    "text2_path = 'Ulysses - James Joyce.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load text and split into sentences\n",
    "def load_text(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read().lower()  # Convert to lowercase\n",
    "\n",
    "    sentences = re.split(r'[.!?]', text)  # Split on sentence boundaries\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]  # Remove empty lines\n",
    "    return sentences\n",
    "\n",
    "# Split into train and test (1000 test sentences, rest train)\n",
    "def split_data(sentences, test_size=1000):\n",
    "    random.shuffle(sentences)  # Shuffle sentences to ensure randomness\n",
    "    test_sentences = sentences[:test_size]\n",
    "    train_sentences = sentences[test_size:]\n",
    "    return train_sentences, test_sentences\n",
    "\n",
    "# Tokenize a list of sentences\n",
    "def tokenize(sentences):\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = re.sub(r\"[^a-zA-Z\\s]\", \"\", sentence).split()  # Remove special chars & split\n",
    "        tokenized_sentences.append(words)\n",
    "    return tokenized_sentences\n",
    "\n",
    "# Build vocabulary from training data only\n",
    "def build_vocab(tokenized_sentences, min_freq=1):\n",
    "    word_counts = Counter(word for sentence in tokenized_sentences for word in sentence)\n",
    "    vocab = {word: idx for idx, (word, freq) in enumerate(word_counts.items()) if freq >= min_freq}\n",
    "    vocab[\"<UNK>\"] = len(vocab)  # Add unknown token\n",
    "    return vocab\n",
    "\n",
    "# Convert words to numerical indices\n",
    "def words_to_indices(sentences, vocab):\n",
    "    indexed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        indexed_sentences.append([vocab.get(word, vocab[\"<UNK>\"]) for word in sentence])\n",
    "    return indexed_sentences\n",
    "\n",
    "# Generate n-gram dataset\n",
    "def create_ngrams(indexed_sentences, n=3):\n",
    "    data = []\n",
    "    for sentence in indexed_sentences:\n",
    "        if len(sentence) >= n:\n",
    "            for i in range(len(sentence) - n):\n",
    "                context = sentence[i : i + n]  # First (n) words\n",
    "                target = sentence[i + n]  # Next word (prediction target)\n",
    "                data.append((context, target))\n",
    "    return data\n",
    "\n",
    "# Convert dataset to PyTorch tensors\n",
    "def prepare_tensors(data):\n",
    "    contexts = torch.tensor([x[0] for x in data], dtype=torch.long)\n",
    "    targets = torch.tensor([x[1] for x in data], dtype=torch.long)\n",
    "    return contexts, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size (1): 6589\n",
      "Train 3-gram Dataset Size (1): 89705\n",
      "Test 3-gram Dataset Size (1): 14391\n",
      "Train 5-gram Dataset Size (1): 78650\n",
      "Test 5-gram Dataset Size (1): 12707\n"
     ]
    }
   ],
   "source": [
    "sentences1 = load_text(text1_path)\n",
    "\n",
    "# Split into train and test (sentence-level split)\n",
    "train_sentences1, test_sentences1 = split_data(sentences1)\n",
    "\n",
    "# Tokenize sentences\n",
    "train_tokens1 = tokenize(train_sentences1)\n",
    "test_tokens1 = tokenize(test_sentences1)\n",
    "\n",
    "# Build vocab from train only\n",
    "train_vocab1 = build_vocab(train_tokens1, min_freq=1)\n",
    "\n",
    "# Convert words to indices\n",
    "train_indices1 = words_to_indices(train_tokens1, train_vocab1)\n",
    "test_indices1 = words_to_indices(test_tokens1, train_vocab1)  # Use same vocab\n",
    "\n",
    "# Generate n-grams\n",
    "train_data_3gram1 = create_ngrams(train_indices1, n=3)\n",
    "test_data_3gram1 = create_ngrams(test_indices1, n=3)\n",
    "\n",
    "train_data_5gram1 = create_ngrams(train_indices1, n=5)\n",
    "test_data_5gram1 = create_ngrams(test_indices1, n=5)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_3gram1, y_train_3gram1 = prepare_tensors(train_data_3gram1)\n",
    "X_test_3gram1, y_test_3gram1 = prepare_tensors(test_data_3gram1)\n",
    "\n",
    "X_train_5gram1, y_train_5gram1 = prepare_tensors(train_data_5gram1)\n",
    "X_test_5gram1, y_test_5gram1 = prepare_tensors(test_data_5gram1)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Vocabulary Size (1): {len(train_vocab1)}\")\n",
    "print(f\"Train 3-gram Dataset Size (1): {len(X_train_3gram1)}\")\n",
    "print(f\"Test 3-gram Dataset Size (1): {len(X_test_3gram1)}\")\n",
    "print(f\"Train 5-gram Dataset Size (1): {len(X_train_5gram1)}\")\n",
    "print(f\"Test 5-gram Dataset Size (1): {len(X_test_5gram1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size (2): 28941\n",
      "Train 3-gram Dataset Size (2): 191657\n",
      "Test 3-gram Dataset Size (2): 7255\n",
      "Train 5-gram Dataset Size (2): 160305\n",
      "Test 5-gram Dataset Size (2): 6012\n"
     ]
    }
   ],
   "source": [
    "sentences2 = load_text(text2_path)\n",
    "\n",
    "# Split into train and test (sentence-level split)\n",
    "train_sentences2, test_sentences2 = split_data(sentences2)\n",
    "\n",
    "# Tokenize sentences\n",
    "train_tokens2 = tokenize(train_sentences2)\n",
    "test_tokens2 = tokenize(test_sentences2)\n",
    "\n",
    "# Build vocab from train only\n",
    "train_vocab2 = build_vocab(train_tokens2, min_freq=1)\n",
    "\n",
    "# Convert words to indices\n",
    "train_indices2 = words_to_indices(train_tokens2, train_vocab2)\n",
    "test_indices2 = words_to_indices(test_tokens2, train_vocab2)  # Use same vocab\n",
    "\n",
    "# Generate n-grams\n",
    "train_data_3gram2 = create_ngrams(train_indices2, n=3)\n",
    "test_data_3gram2 = create_ngrams(test_indices2, n=3)\n",
    "\n",
    "train_data_5gram2 = create_ngrams(train_indices2, n=5)\n",
    "test_data_5gram2 = create_ngrams(test_indices2, n=5)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_3gram2, y_train_3gram2 = prepare_tensors(train_data_3gram2)\n",
    "X_test_3gram2, y_test_3gram2 = prepare_tensors(test_data_3gram2)\n",
    "\n",
    "X_train_5gram2, y_train_5gram2 = prepare_tensors(train_data_5gram2)\n",
    "X_test_5gram2, y_test_5gram2 = prepare_tensors(test_data_5gram2)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Vocabulary Size (2): {len(train_vocab2)}\")\n",
    "print(f\"Train 3-gram Dataset Size (2): {len(X_train_3gram2)}\")\n",
    "print(f\"Test 3-gram Dataset Size (2): {len(X_test_3gram2)}\")\n",
    "print(f\"Train 5-gram Dataset Size (2): {len(X_train_5gram2)}\")\n",
    "print(f\"Test 5-gram Dataset Size (2): {len(X_test_5gram2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from indices to words (inverse of train_vocab)\n",
    "idx_to_word1 = {idx: word for word, idx in train_vocab1.items()}\n",
    "idx_to_word2 = {idx: word for word, idx in train_vocab2.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FFNNLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, context_size, embedding_dim=100, hidden_dim=256):\n",
    "        super(FFNNLanguageModel, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Flatten the embeddings and feed through fully connected layers\n",
    "        self.ff_layers = nn.Sequential(\n",
    "            nn.Linear(context_size * embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, vocab_size)\n",
    "        )\n",
    "        \n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, context_size)\n",
    "        embeds = self.embeddings(x)  # (batch_size, context_size, embedding_dim)\n",
    "        \n",
    "        # Flatten the embeddings\n",
    "        batch_size = embeds.shape[0]\n",
    "        flattened = embeds.view(batch_size, -1)\n",
    "        \n",
    "        # Feed through layers\n",
    "        hidden = self.ff_layers(flattened)\n",
    "        log_probs = self.log_softmax(hidden)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTracker:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            'model_name': [],\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'test_loss': [],\n",
    "            'train_perplexity': [],\n",
    "            'test_perplexity': []\n",
    "        }\n",
    "    \n",
    "    def add_epoch_metrics(self, model_name, epoch, train_loss, test_loss):\n",
    "        self.metrics['model_name'].append(model_name)\n",
    "        self.metrics['epoch'].append(epoch)\n",
    "        self.metrics['train_loss'].append(train_loss)\n",
    "        self.metrics['test_loss'].append(test_loss)\n",
    "        self.metrics['train_perplexity'].append(None)  # Will be updated later\n",
    "        self.metrics['test_perplexity'].append(None)\n",
    "    \n",
    "    def update_final_perplexity(self, model_name, train_perp, test_perp):\n",
    "        mask = (self.metrics['model_name'] == model_name)\n",
    "        self.metrics['train_perplexity'][-1] = train_perp\n",
    "        self.metrics['test_perplexity'][-1] = test_perp\n",
    "    \n",
    "    def save_metrics(self, filename='model_metrics.csv'):\n",
    "        df = pd.DataFrame(self.metrics)\n",
    "        df.to_csv(filename, index=False)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Function to calculate Perplexity and Saving them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_directories():\n",
    "    \"\"\"Create necessary directories if they don't exist\"\"\"\n",
    "    directories = ['Models', 'Perplexity']\n",
    "    for directory in directories:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "def calculate_sentence_perplexity(model, sentence_indices, context_size, device='cuda'):\n",
    "    \"\"\"Calculate perplexity for a single sentence\"\"\"\n",
    "    if len(sentence_indices) <= context_size:\n",
    "        return float('inf')\n",
    "    \n",
    "    model.eval()\n",
    "    total_log_prob = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(sentence_indices) - context_size):\n",
    "        context = torch.tensor([sentence_indices[i:i+context_size]], device=device)\n",
    "        target = torch.tensor([sentence_indices[i+context_size]], device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            log_probs = model(context)\n",
    "            total_log_prob += -log_probs[0][target].item()\n",
    "            count += 1\n",
    "    \n",
    "    return np.exp(total_log_prob / count) if count > 0 else float('inf')\n",
    "\n",
    "def save_perplexity_results(corpus_name, n_gram, dataset_type, sentences_indices, perplexities):\n",
    "    \"\"\"Save perplexity results to file\"\"\"\n",
    "    file_name = f\"2021102040_ffnn_{corpus_name}_N{n_gram}_{dataset_type}-perplexity.txt\"\n",
    "    file_path = os.path.join('Perplexity', file_name)\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        avg_perplexity = np.mean([p for p in perplexities if p != float('inf')])\n",
    "        f.write(f\"Overall Average Perplexity: {avg_perplexity:.2f}\\n\\n\")\n",
    "        \n",
    "        for idx, (sentence, perp) in enumerate(zip(sentences_indices, perplexities), 1):\n",
    "            f.write(f\" {sentence} - Perplexity: {perp:.2f}\\n\")\n",
    "\n",
    "def evaluate_and_save_perplexity(model, sentences_indices, context_size, corpus_name, n_gram, dataset_type, device='cpu'):\n",
    "    \"\"\"Evaluate perplexity for each sentence and save results\"\"\"\n",
    "    perplexities = []\n",
    "    \n",
    "    for sentence in sentences_indices:\n",
    "        if len(sentence) > context_size:\n",
    "            perp = calculate_sentence_perplexity(model, sentence, context_size, device)\n",
    "            if perp != float('inf'):\n",
    "                perplexities.append(perp)\n",
    "    \n",
    "    save_perplexity_results(corpus_name, n_gram, dataset_type, sentences_indices, perplexities)\n",
    "    return np.mean(perplexities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Training The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def train_and_evaluate_model(model, train_data, test_data, corpus_name, n_gram, word_to_idx, device='cpu', batch_size=64, num_epochs=5):\n",
    "    \"\"\"Complete training and evaluation pipeline with vocabulary saving\"\"\"\n",
    "    ensure_directories()\n",
    "    model_tracker = ModelTracker()\n",
    "    \n",
    "    # Create model name for saving\n",
    "    model_name = f\"2021102040_ffnn_{corpus_name}_N{n_gram}\"\n",
    "    model_path = os.path.join('Models', f\"{model_name}.pth\")  # Changed to .pth for clarity\n",
    "    \n",
    "    # Prepare data loaders\n",
    "    train_loader = DataLoader(TensorDataset(*train_data), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(*test_data), batch_size=batch_size)\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_test_loss = float('inf')\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Training for Epoch: {epoch+1}')\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output, batch_y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                output = model(batch_x)\n",
    "                loss = criterion(output, batch_y)\n",
    "                total_test_loss += loss.item()\n",
    "        \n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        \n",
    "        # Save best model with vocabulary\n",
    "        if avg_test_loss < best_test_loss:\n",
    "            best_test_loss = avg_test_loss\n",
    "            save_dict = {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"word_to_idx\": word_to_idx,  # Save vocabulary\n",
    "                \"vocab_size\": len(word_to_idx)\n",
    "            }\n",
    "            torch.save(save_dict, model_path)\n",
    "        \n",
    "        # Track metrics\n",
    "        model_tracker.add_epoch_metrics(model_name, epoch+1, avg_train_loss, avg_test_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Training Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    # Load best model for evaluation\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, model_tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments(experiment_data, train_vocab1, train_vocab2, device='cpu'):\n",
    "    \"\"\"Run all experiments for both corpora and both n-gram sizes\"\"\"\n",
    "    all_metrics = []\n",
    "    \n",
    "    for corpus_name in ['corpus1', 'corpus2']:\n",
    "        vocab = train_vocab1 if corpus_name == 'corpus1' else train_vocab2  \n",
    "        \n",
    "        for n_gram in [3, 5]:\n",
    "            print(f\"\\nTraining {corpus_name} with {n_gram}-gram model\")\n",
    "            \n",
    "            # Get the data for this experiment\n",
    "            train_data = experiment_data[corpus_name][n_gram]['train']\n",
    "            test_data = experiment_data[corpus_name][n_gram]['test']\n",
    "            \n",
    "            # Initialize model\n",
    "            model = FFNNLanguageModel(\n",
    "                vocab_size=len(vocab),\n",
    "                context_size=n_gram,\n",
    "                embedding_dim=100,\n",
    "                hidden_dim=256\n",
    "            ).to(device)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model, tracker = train_and_evaluate_model(\n",
    "                model,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                corpus_name,\n",
    "                n_gram,\n",
    "                vocab,\n",
    "                device\n",
    "            )\n",
    "            \n",
    "            all_metrics.append(tracker)\n",
    "    \n",
    "    # Combine and save all metrics\n",
    "    combined_metrics = pd.concat([pd.DataFrame(tracker.metrics) for tracker in all_metrics])\n",
    "    combined_metrics.to_csv('ffnn_all_metrics.csv', index=False)\n",
    "    \n",
    "    return combined_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For corpus 1 (Pride and Prejudice)\n",
    "train_data1_3gram = (X_train_3gram1, y_train_3gram1)  # These are already tensors\n",
    "test_data1_3gram = (X_test_3gram1, y_test_3gram1)\n",
    "\n",
    "train_data1_5gram = (X_train_5gram1, y_train_5gram1)\n",
    "test_data1_5gram = (X_test_5gram1, y_test_5gram1)\n",
    "\n",
    "# For corpus 2 (Ulysses)\n",
    "train_data2_3gram = (X_train_3gram2, y_train_3gram2)\n",
    "test_data2_3gram = (X_test_3gram2, y_test_3gram2)\n",
    "\n",
    "train_data2_5gram = (X_train_5gram2, y_train_5gram2)\n",
    "test_data2_5gram = (X_test_5gram2, y_test_5gram2)\n",
    "\n",
    "# Create a dictionary to store the data\n",
    "experiment_data = {\n",
    "    'corpus1': {\n",
    "        3: {'train': train_data1_3gram, 'test': test_data1_3gram},\n",
    "        5: {'train': train_data1_5gram, 'test': test_data1_5gram}\n",
    "    },\n",
    "    'corpus2': {\n",
    "        3: {'train': train_data2_3gram, 'test': test_data2_3gram},\n",
    "        5: {'train': train_data2_5gram, 'test': test_data2_5gram}\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training corpus1 with 3-gram model\n",
      "Training for Epoch: 1\n",
      "Epoch [1/5]\n",
      "Training Loss: 6.2643\n",
      "Test Loss: 5.9381\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 2\n",
      "Epoch [2/5]\n",
      "Training Loss: 5.6886\n",
      "Test Loss: 5.7628\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 3\n",
      "Epoch [3/5]\n",
      "Training Loss: 5.3843\n",
      "Test Loss: 5.7431\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 4\n",
      "Epoch [4/5]\n",
      "Training Loss: 5.1597\n",
      "Test Loss: 5.7674\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 5\n",
      "Epoch [5/5]\n",
      "Training Loss: 4.9792\n",
      "Test Loss: 5.8399\n",
      "--------------------------------------------------\n",
      "\n",
      "Training corpus1 with 5-gram model\n",
      "Training for Epoch: 1\n",
      "Epoch [1/5]\n",
      "Training Loss: 6.3483\n",
      "Test Loss: 6.0485\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 2\n",
      "Epoch [2/5]\n",
      "Training Loss: 5.8030\n",
      "Test Loss: 5.8999\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 3\n",
      "Epoch [3/5]\n",
      "Training Loss: 5.4708\n",
      "Test Loss: 5.8469\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 4\n",
      "Epoch [4/5]\n",
      "Training Loss: 5.2278\n",
      "Test Loss: 5.8803\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 5\n",
      "Epoch [5/5]\n",
      "Training Loss: 5.0281\n",
      "Test Loss: 5.9362\n",
      "--------------------------------------------------\n",
      "\n",
      "Training corpus2 with 3-gram model\n",
      "Training for Epoch: 1\n",
      "Epoch [1/5]\n",
      "Training Loss: 7.4960\n",
      "Test Loss: 7.3077\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 2\n",
      "Epoch [2/5]\n",
      "Training Loss: 7.1208\n",
      "Test Loss: 7.3135\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 3\n",
      "Epoch [3/5]\n",
      "Training Loss: 6.9117\n",
      "Test Loss: 7.4533\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 4\n",
      "Epoch [4/5]\n",
      "Training Loss: 6.7388\n",
      "Test Loss: 7.6013\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 5\n",
      "Epoch [5/5]\n",
      "Training Loss: 6.5948\n",
      "Test Loss: 7.7684\n",
      "--------------------------------------------------\n",
      "\n",
      "Training corpus2 with 5-gram model\n",
      "Training for Epoch: 1\n",
      "Epoch [1/5]\n",
      "Training Loss: 7.5534\n",
      "Test Loss: 7.4372\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 2\n",
      "Epoch [2/5]\n",
      "Training Loss: 7.1926\n",
      "Test Loss: 7.4765\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 3\n",
      "Epoch [3/5]\n",
      "Training Loss: 6.9887\n",
      "Test Loss: 7.5811\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 4\n",
      "Epoch [4/5]\n",
      "Training Loss: 6.8278\n",
      "Test Loss: 7.7387\n",
      "--------------------------------------------------\n",
      "Training for Epoch: 5\n",
      "Epoch [5/5]\n",
      "Training Loss: 6.6934\n",
      "Test Loss: 7.8888\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "metrics_df = run_all_experiments(\n",
    "    experiment_data,\n",
    "    train_vocab1,\n",
    "    train_vocab2,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Calculating and Saving Perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perplexity_df = pd.DataFrame(columns=['model_name', 'train_perplexity', 'test_perplexity'])\n",
    "\n",
    "perplexity_df = pd.DataFrame({\n",
    "    'model_name': pd.Series(dtype='str'),  # Or 'object'\n",
    "    'train_perplexity': pd.Series(dtype='float'),\n",
    "    'test_perplexity': pd.Series(dtype='float')\n",
    "})\n",
    "perplexity_df = pd.DataFrame([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity for N = 3; Corpus - Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNNLanguageModel(\n",
       "  (embeddings): Embedding(6662, 100)\n",
       "  (ff_layers): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=6662, bias=True)\n",
       "  )\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3gram1 = FFNNLanguageModel(vocab_size=len(train_vocab1), context_size=3, embedding_dim=100, hidden_dim=256)\n",
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus1_N3.pth\")\n",
    "model_3gram1.load_state_dict(checkpoint[\"model_state_dict\"])  # Corrected key\n",
    "\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]  # Retrieve the vocabulary mapping if stored\n",
    "\n",
    "model_3gram1.to(device)\n",
    "model_3gram1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3gram1 = FFNNLanguageModel(vocab_size=len(train_vocab1), context_size=3, embedding_dim=100, hidden_dim=256)\n",
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus1_N3.pth\")\n",
    "model_3gram1.load_state_dict(checkpoint[\"model_state_dict\"])  # Corrected key\n",
    "\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]  # Retrieve the vocabulary mapping if stored\n",
    "\n",
    "model_3gram1.to(device)\n",
    "model_3gram1.eval()\n",
    "\n",
    "print(\"\\nCalculating training perplexity...\")\n",
    "train_perplexity = evaluate_and_save_perplexity(model_3gram1,train_indices1,context_size=3,corpus_name='corpus1',n_gram=3,dataset_type='train',device=device)\n",
    "print(\"Calculating test perplexity...\")\n",
    "test_perplexity = evaluate_and_save_perplexity(model_3gram1,test_indices1,context_size=3,corpus_name='corpus1',n_gram=3,dataset_type='test',device=device)\n",
    "\n",
    "print(\"\\nFinal Results for 3-gram Model (Corpus 1):\")\n",
    "print(f\"Training Perplexity: {train_perplexity:.2f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "\n",
    "new_row = pd.Series({'model_name': \"N = 3; Corpus 1\", 'train_perplexity': train_perplexity, 'test_perplexity': test_perplexity})\n",
    "perplexity_df = pd.concat([perplexity_df, new_row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity for N = 5; Corpus - Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5gram1 = FFNNLanguageModel(vocab_size=len(train_vocab1), context_size=5, embedding_dim=100, hidden_dim=256)\n",
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus1_N5.pth\")\n",
    "\n",
    "model_5gram1.load_state_dict(checkpoint[\"model_state_dict\"])  # Load weights\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]  # Load vocabulary mapping if stored\n",
    "\n",
    "model_5gram1.to(device)\n",
    "model_5gram1.eval()\n",
    "\n",
    "print(\"\\nCalculating training perplexity...\")\n",
    "train_perplexity = evaluate_and_save_perplexity(model_5gram1, train_indices1, context_size=5, corpus_name='corpus1', n_gram=5, dataset_type='train', device=device)\n",
    "print(\"Calculating test perplexity...\")\n",
    "test_perplexity = evaluate_and_save_perplexity(model_5gram1, test_indices1, context_size=5, corpus_name='corpus1', n_gram=5, dataset_type='test', device=device)\n",
    "\n",
    "print(\"\\nFinal Results for 5-gram Model (Corpus 1):\")\n",
    "print(f\"Training Perplexity: {train_perplexity:.2f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "\n",
    "new_row = pd.Series({'model_name': \"N = 5; Corpus 1\", 'train_perplexity': train_perplexity, 'test_perplexity': test_perplexity})\n",
    "perplexity_df = pd.concat([perplexity_df, new_row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity for N = 3; Corpus - Ulysses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating training perplexity...\n",
      "Calculating test perplexity...\n",
      "\n",
      "Final Results for 3-gram Model (Corpus 2):\n",
      "Training Perplexity: 10943.37\n",
      "Test Perplexity: 14530.91\n"
     ]
    }
   ],
   "source": [
    "model_3gram2 = FFNNLanguageModel(vocab_size=len(train_vocab2), context_size=3, embedding_dim=100, hidden_dim=256)\n",
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus2_N3.pth\")\n",
    "\n",
    "model_3gram2.load_state_dict(checkpoint[\"model_state_dict\"])  # Load weights\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]  # Load vocabulary mapping if stored\n",
    "\n",
    "model_3gram2.to(device)\n",
    "model_3gram2.eval()\n",
    "\n",
    "print(\"\\nCalculating training perplexity...\")\n",
    "train_perplexity = evaluate_and_save_perplexity(model_3gram2, train_indices2, context_size=3, corpus_name='corpus2', n_gram=3, dataset_type='train', device=device)\n",
    "print(\"Calculating test perplexity...\")\n",
    "test_perplexity = evaluate_and_save_perplexity(model_3gram2, test_indices2, context_size=3, corpus_name='corpus2', n_gram=3, dataset_type='test', device=device)\n",
    "\n",
    "print(\"\\nFinal Results for 3-gram Model (Corpus 2):\")\n",
    "print(f\"Training Perplexity: {train_perplexity:.2f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "\n",
    "new_row = pd.Series({'model_name': \"N = 3; Corpus 2\", 'train_perplexity': train_perplexity, 'test_perplexity': test_perplexity})\n",
    "perplexity_df = pd.concat([perplexity_df, new_row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity for N = 5; Corpus - Ulysses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating training perplexity...\n",
      "Calculating test perplexity...\n",
      "\n",
      "Final Results for 5-gram Model (Corpus 2):\n",
      "Training Perplexity: 8193.14\n",
      "Test Perplexity: 19272.27\n"
     ]
    }
   ],
   "source": [
    "model_5gram2 = FFNNLanguageModel(vocab_size=len(train_vocab2), context_size=5, embedding_dim=100, hidden_dim=256)\n",
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus2_N5.pth\")\n",
    "\n",
    "model_5gram2.load_state_dict(checkpoint[\"model_state_dict\"])  # Load weights\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]  # Load vocabulary mapping if stored\n",
    "\n",
    "model_5gram2.to(device)\n",
    "model_5gram2.eval()\n",
    "\n",
    "print(\"\\nCalculating training perplexity...\")\n",
    "train_perplexity = evaluate_and_save_perplexity(model_5gram2, train_indices2, context_size=5, corpus_name='corpus2', n_gram=5, dataset_type='train', device=device)\n",
    "print(\"Calculating test perplexity...\")\n",
    "test_perplexity = evaluate_and_save_perplexity(model_5gram2, test_indices2, context_size=5, corpus_name='corpus2', n_gram=5, dataset_type='test', device=device)\n",
    "\n",
    "print(\"\\nFinal Results for 5-gram Model (Corpus 2):\")\n",
    "print(f\"Training Perplexity: {train_perplexity:.2f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "\n",
    "new_row = pd.Series({'model_name': \"N = 5; Corpus 2\", 'train_perplexity': train_perplexity, 'test_perplexity': test_perplexity})\n",
    "perplexity_df = pd.concat([perplexity_df, new_row.to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_perplexity</th>\n",
       "      <th>test_perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N = 3; Corpus 1</td>\n",
       "      <td>396.950281</td>\n",
       "      <td>6805.919115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N = 5; Corpus 1</td>\n",
       "      <td>443.198667</td>\n",
       "      <td>185495.097141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N = 3; Corpus 2</td>\n",
       "      <td>10943.366095</td>\n",
       "      <td>14530.913292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N = 5; Corpus 2</td>\n",
       "      <td>8193.136195</td>\n",
       "      <td>19272.271428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_name train_perplexity test_perplexity\n",
       "0  N = 3; Corpus 1       396.950281     6805.919115\n",
       "1  N = 5; Corpus 1       443.198667   185495.097141\n",
       "2  N = 3; Corpus 2     10943.366095    14530.913292\n",
       "3  N = 5; Corpus 2      8193.136195    19272.271428"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Predicting Next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Context: having never even\n",
      "Actual next word: fancied\n",
      "Top 5 predictions:\n",
      "to: 0.0126\n",
      "the: 0.0100\n",
      "and: 0.0093\n",
      "of: 0.0082\n",
      "be: 0.0079\n",
      "\n",
      "Context: never even fancied\n",
      "Actual next word: herself\n",
      "Top 5 predictions:\n",
      "and: 0.0434\n",
      "the: 0.0376\n",
      "to: 0.0291\n",
      "that: 0.0281\n",
      "of: 0.0209\n",
      "\n",
      "Context: even fancied herself\n",
      "Actual next word: in\n",
      "Top 5 predictions:\n",
      "as: 0.0535\n",
      "and: 0.0445\n",
      "to: 0.0362\n",
      "of: 0.0348\n",
      "in: 0.0269\n"
     ]
    }
   ],
   "source": [
    "def generate_prediction(model, context, idx_to_word, top_k=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        context_tensor = torch.tensor([context], device=device)\n",
    "        log_probs = model(context_tensor)\n",
    "        probs = torch.exp(log_probs)\n",
    "        top_k_probs, top_k_indices = torch.topk(probs[0], k=top_k)\n",
    "        \n",
    "        predictions = [(idx_to_word[idx.item()], prob.item()) \n",
    "                      for idx, prob in zip(top_k_indices, top_k_probs)]\n",
    "    return predictions\n",
    "\n",
    "# Print some sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i in range(3):  # Show 3 random examples\n",
    "    if len(X_test_3gram1) > i:\n",
    "        context = X_test_3gram1[i].tolist()\n",
    "        actual = idx_to_word1[y_test_3gram1[i].item()]\n",
    "        context_words = [idx_to_word1[idx] for idx in context]\n",
    "        \n",
    "        print(f\"\\nContext: {' '.join(context_words)}\")\n",
    "        print(f\"Actual next word: {actual}\")\n",
    "        print(\"Top 5 predictions:\")\n",
    "        predictions = generate_prediction(model_3gram1, context, idx_to_word1)\n",
    "        for word, prob in predictions:\n",
    "            print(f\"{word}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, sentence, word_to_idx, idx_to_word, context_size=3, device='cpu', top_k=5):\n",
    "    sentence = sentence.lower()\n",
    "    words = re.sub(r\"[^a-zA-Z\\s]\", \"\", sentence).split()\n",
    "    if len(words) < context_size:\n",
    "        raise ValueError(f\"Input sentence must have at least {context_size} words\")\n",
    "    \n",
    "    context_words = words[-context_size:]\n",
    "    context_indices = [word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in context_words]\n",
    "    context_tensor = torch.tensor([context_indices], dtype=torch.long).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        log_probs = model(context_tensor)\n",
    "        probs = torch.exp(log_probs)\n",
    "        top_k_probs, top_k_indices = torch.topk(probs[0], k=top_k)\n",
    "        \n",
    "        predictions = [(idx_to_word[idx.item()], prob.item()) \n",
    "                      for idx, prob in zip(top_k_indices, top_k_probs)]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def print_predictions(sentence, predictions):\n",
    "    print(f\"\\nInput sentence: {sentence}\")\n",
    "    print(\"Top 5 predicted next words:\")\n",
    "    for word, prob in predictions:\n",
    "        print(f\"{word}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing On Saved Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 gram model , Corpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNNLanguageModel(\n",
       "  (embeddings): Embedding(6662, 100)\n",
       "  (ff_layers): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=6662, bias=True)\n",
       "  )\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus1_N3.pth\")\n",
    "\n",
    "# Load the saved vocabulary\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]\n",
    "vocab_size = checkpoint[\"vocab_size\"]\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Ensure vocab size is the same before initializing the model\n",
    "model_3gram1 = FFNNLanguageModel(vocab_size=vocab_size, context_size=3, embedding_dim=100, hidden_dim=256)\n",
    "model_3gram1.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model_3gram1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sentence: the cat sat on a mat\n",
      "Top 5 predicted next words:\n",
      "of: 0.0351\n",
      "and: 0.0210\n",
      "to: 0.0140\n",
      "which: 0.0140\n",
      "who: 0.0122\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "custom_sentence = \"the cat sat on a mat\"\n",
    "predictions = predict_next_word(\n",
    "    model=model_3gram1,\n",
    "    sentence=custom_sentence,\n",
    "    word_to_idx=word_to_idx,\n",
    "    idx_to_word=idx_to_word,\n",
    "    context_size=3\n",
    ")\n",
    "\n",
    "print_predictions(custom_sentence, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 gram model , Corpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNNLanguageModel(\n",
       "  (embeddings): Embedding(6662, 100)\n",
       "  (ff_layers): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=6662, bias=True)\n",
       "  )\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus1_N5.pth\")\n",
    "\n",
    "# Load the saved vocabulary\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]\n",
    "vocab_size = checkpoint[\"vocab_size\"]\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Ensure vocab size is the same before initializing the model\n",
    "model_5gram1 = FFNNLanguageModel(vocab_size=vocab_size, context_size=5, embedding_dim=100, hidden_dim=256)\n",
    "model_5gram1.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model_5gram1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sentence: the cat sat on a mat\n",
      "Top 5 predicted next words:\n",
      "of: 0.1075\n",
      "and: 0.0875\n",
      "to: 0.0442\n",
      "which: 0.0434\n",
      "in: 0.0285\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "custom_sentence = \"the cat sat on a mat\"\n",
    "predictions = predict_next_word(\n",
    "    model=model_5gram1,\n",
    "    sentence=custom_sentence,\n",
    "    word_to_idx=word_to_idx,\n",
    "    idx_to_word=idx_to_word,\n",
    "    context_size=5\n",
    ")\n",
    "\n",
    "print_predictions(custom_sentence, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 gram model , Corpus 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNNLanguageModel(\n",
       "  (embeddings): Embedding(29101, 100)\n",
       "  (ff_layers): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=29101, bias=True)\n",
       "  )\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus2_N3.pth\")\n",
    "\n",
    "# Load the saved vocabulary\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]\n",
    "vocab_size = checkpoint[\"vocab_size\"]\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Ensure vocab size is the same before initializing the model\n",
    "model_3gram2 = FFNNLanguageModel(vocab_size=vocab_size, context_size=3, embedding_dim=100, hidden_dim=256)\n",
    "model_3gram2.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model_3gram2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sentence: the cat sat on a mat\n",
      "Top 5 predicted next words:\n",
      "of: 0.0264\n",
      "and: 0.0146\n",
      "the: 0.0092\n",
      "in: 0.0088\n",
      "to: 0.0075\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "custom_sentence = \"the cat sat on a mat\"\n",
    "predictions = predict_next_word(\n",
    "    model=model_3gram2,\n",
    "    sentence=custom_sentence,\n",
    "    word_to_idx=word_to_idx,\n",
    "    idx_to_word=idx_to_word,\n",
    "    context_size=3\n",
    ")\n",
    "\n",
    "print_predictions(custom_sentence, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 gram model , Corpus 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNNLanguageModel(\n",
       "  (embeddings): Embedding(29101, 100)\n",
       "  (ff_layers): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=29101, bias=True)\n",
       "  )\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Models/2021102040_ffnn_corpus2_N5.pth\")\n",
    "\n",
    "# Load the saved vocabulary\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]\n",
    "vocab_size = checkpoint[\"vocab_size\"]\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Ensure vocab size is the same before initializing the model\n",
    "model_5gram2 = FFNNLanguageModel(vocab_size=vocab_size, context_size=5, embedding_dim=100, hidden_dim=256)\n",
    "model_5gram2.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model_5gram2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sentence: the cat sat on a mat\n",
      "Top 5 predicted next words:\n",
      "of: 0.0211\n",
      "and: 0.0134\n",
      "the: 0.0097\n",
      "in: 0.0080\n",
      "to: 0.0067\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "custom_sentence = \"the cat sat on a mat\"\n",
    "predictions = predict_next_word(\n",
    "    model=model_5gram2,\n",
    "    sentence=custom_sentence,\n",
    "    word_to_idx=word_to_idx,\n",
    "    idx_to_word=idx_to_word,\n",
    "    context_size=5\n",
    ")\n",
    "\n",
    "print_predictions(custom_sentence, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        Initialize the Vanilla RNN model.\n",
    "        \n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary\n",
    "            embedding_dim (int): Dimension of word embeddings\n",
    "            hidden_dim (int): Dimension of hidden state\n",
    "        \"\"\"\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # Word embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length)\n",
    "            hidden (torch.Tensor, optional): Initial hidden state\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (output probabilities, final hidden state)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Initialize hidden state if not provided\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(1, batch_size, self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Embed input words\n",
    "        embedded = self.embedding(x)  # Shape: (batch_size, sequence_length, embedding_dim)\n",
    "        \n",
    "        # Pass through RNN\n",
    "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
    "        # rnn_out shape: (batch_size, sequence_length, hidden_dim)\n",
    "        # hidden shape: (1, batch_size, hidden_dim)\n",
    "        \n",
    "        # Pass through final layer\n",
    "        output = self.fc(rnn_out)  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def predict_next_word(self, context, idx_to_word, top_k=5):\n",
    "        \"\"\"\n",
    "        Predict the next word given a context.\n",
    "        \n",
    "        Args:\n",
    "            context (torch.Tensor): Input context tensor\n",
    "            idx_to_word (dict): Mapping from indices to words\n",
    "            top_k (int): Number of top predictions to return\n",
    "            \n",
    "        Returns:\n",
    "            list: Top k predicted words with their probabilities\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            output, _ = self(context)\n",
    "            probabilities = torch.softmax(output[:, -1], dim=-1)\n",
    "            top_probs, top_indices = torch.topk(probabilities, top_k)\n",
    "            \n",
    "            predictions = [\n",
    "                (idx_to_word[idx.item()], prob.item())\n",
    "                for idx, prob in zip(top_indices[0], top_probs[0])\n",
    "            ]\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "def train_rnn(model, train_data, criterion, optimizer, num_epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Train the RNN model.\n",
    "    \n",
    "    Args:\n",
    "        model (VanillaRNN): The RNN model\n",
    "        train_data (tuple): Tuple of (X_train, y_train)\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        num_epochs (int): Number of training epochs\n",
    "        batch_size (int): Batch size\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    dataset_size = len(X_train)\n",
    "    loss_df = []\n",
    "    print(f'Training ....')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        # Create batches\n",
    "        for i in range(0, dataset_size, batch_size):\n",
    "            batch_X = X_train[i:i + batch_size]\n",
    "            batch_y = y_train[i:i + batch_size]\n",
    "            \n",
    "            # Forward pass\n",
    "            output, _ = model(batch_X)\n",
    "            loss = criterion(output[:, -1], batch_y)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / (dataset_size // batch_size)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "        loss_df.append(avg_loss)\n",
    "    \n",
    "    return loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_helper(model,X_train,y_train,batch_size = 32,N_epochs = 5,learning_rate = 0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    loss_df = train_rnn(\n",
    "        model,\n",
    "        (X_train, y_train),\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        N_epochs,\n",
    "        batch_size\n",
    "    )\n",
    "    return loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Training on Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ....\n",
      "Epoch 1/5, Loss: 5.9888\n",
      "Epoch 2/5, Loss: 5.0141\n",
      "Epoch 3/5, Loss: 4.4084\n",
      "Epoch 4/5, Loss: 3.9088\n",
      "Epoch 5/5, Loss: 3.5051\n"
     ]
    }
   ],
   "source": [
    "# Initialize model for the first text (Pride and Prejudice)\n",
    "model_rnn_1 = VanillaRNN(\n",
    "    vocab_size=len(train_vocab1),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM\n",
    ")\n",
    "\n",
    "loss1 = train_helper(model_rnn_1,X_train_3gram1,y_train_3gram1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model and metadata saved at: Models/2021102040_rnn_corpus1.pth\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "model_path = \"Models/2021102040_rnn_corpus1.pth\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "\n",
    "# Save all required components\n",
    "save_data = {\n",
    "    \"model_state_dict\": model_rnn_1.state_dict(),  # Model weights\n",
    "    \"word_to_idx\": train_vocab1,  # Vocabulary mapping\n",
    "    \"idx_to_word\": idx_to_word1,  # Reverse mapping\n",
    "    \"hyperparams\": {\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"vocab_size\": len(train_vocab1)    },\n",
    "}\n",
    "\n",
    "torch.save(save_data, model_path)\n",
    "\n",
    "print(f\" Model and metadata saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Training on Ulysses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ....\n",
      "Epoch 1/5, Loss: 7.5252\n",
      "Epoch 2/5, Loss: 6.1271\n",
      "Epoch 3/5, Loss: 5.2261\n",
      "Epoch 4/5, Loss: 4.4929\n",
      "Epoch 5/5, Loss: 3.9424\n"
     ]
    }
   ],
   "source": [
    "# Initialize model for the first text (Pride and Prejudice)\n",
    "model_rnn_2 = VanillaRNN(\n",
    "    vocab_size=len(train_vocab2),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM\n",
    ")\n",
    "\n",
    "loss2 = train_helper(model_rnn_2,X_train_3gram2,y_train_3gram2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model and metadata saved at: Models/2021102040_rnn_corpus2.pth\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "model_path = \"Models/2021102040_rnn_corpus2.pth\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "\n",
    "# Save all required components\n",
    "save_data = {\n",
    "    \"model_state_dict\": model_rnn_2.state_dict(),  # Model weights\n",
    "    \"word_to_idx\": train_vocab2,  # Vocabulary mapping\n",
    "    \"idx_to_word\": idx_to_word2,  # Reverse mapping\n",
    "    \"hyperparams\": {\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"vocab_size\": len(train_vocab2)    },\n",
    "}\n",
    "\n",
    "torch.save(save_data, model_path)\n",
    "\n",
    "print(f\" Model and metadata saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Epoch Wise Loss for both Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch  Pride and Prejudice   Ulysses\n",
      "0      1             5.988782  7.525239\n",
      "1      2             5.014135  6.127071\n",
      "2      3             4.408369  5.226066\n",
      "3      4             3.908786  4.492947\n",
      "4      5             3.505142  3.942395\n"
     ]
    }
   ],
   "source": [
    "loss_df = pd.DataFrame({\n",
    "    'Epoch': list(range(1, 6)),  # Epochs 1 to 5\n",
    "    'Pride and Prejudice': loss1,\n",
    "    'Ulysses': loss2\n",
    "})\n",
    "\n",
    "# Saving to a CSV file (optional)\n",
    "loss_df.to_csv('rnn_loss_data.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(loss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Perplexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_sentence_perplexity_rnn(model, sentence_indices, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Convert sentence indices to tensor and move to device\n",
    "    sentence_tensor = torch.tensor(sentence_indices, dtype=torch.long, device=device).unsqueeze(0)  # Shape: (1, seq_len)\n",
    "    \n",
    "    # Initialize hidden state directly here instead of calling init_hidden()\n",
    "    batch_size = sentence_tensor.shape[0]  # Should be 1\n",
    "    hidden = torch.zeros(1, batch_size, model.hidden_dim, device=device)  # Manually initialized hidden state\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sentence_indices) - 1):  # Predict each word given previous ones\n",
    "            input_word = sentence_tensor[:, i].unsqueeze(1)  # Shape: (1, 1)\n",
    "            target_word = sentence_tensor[:, i + 1]  # Shape: (1,)\n",
    "\n",
    "            output, hidden = model(input_word, hidden)  # Forward pass\n",
    "\n",
    "            output = output.squeeze(1)  # Remove sequence dimension (1, vocab_size)\n",
    "            loss = loss_function(output, target_word)  # Compute loss\n",
    "            total_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "    avg_loss = total_loss / count if count > 0 else float('inf')\n",
    "    perplexity = torch.exp(torch.tensor(avg_loss)).item()  # Convert loss to perplexity\n",
    "\n",
    "    return perplexity\n",
    "\n",
    "def save_perplexity_results_rnn(corpus_name, dataset_type, sentences_indices, perplexities):\n",
    "    \"\"\"Save perplexity results to file for RNN\"\"\"\n",
    "    file_name = f\"2021102040_rnn_{corpus_name}_{dataset_type}-perplexity.txt\"\n",
    "    file_path = os.path.join('Perplexity', file_name)\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        avg_perplexity = np.mean([p for p in perplexities if p != float('inf')])\n",
    "        f.write(f\"Overall Average Perplexity: {avg_perplexity:.2f}\\n\\n\")\n",
    "        \n",
    "        for idx, (sentence, perp) in enumerate(zip(sentences_indices, perplexities), 1):\n",
    "            f.write(f\" {sentence} - Perplexity: {perp:.2f}\\n\")\n",
    "\n",
    "def evaluate_and_save_perplexity_rnn(model, sentences_indices, corpus_name, dataset_type, device='cpu'):\n",
    "    \"\"\"Evaluate perplexity for each sentence using an RNN and save results\"\"\"\n",
    "    perplexities = []\n",
    "\n",
    "    for sentence in sentences_indices:\n",
    "        if len(sentence) > 1:  # Ensure valid sentence length\n",
    "            perp = calculate_sentence_perplexity_rnn(model, sentence, device)\n",
    "            if perp != float('inf'):\n",
    "                perplexities.append(perp)\n",
    "\n",
    "    save_perplexity_results_rnn(corpus_name, dataset_type, sentences_indices, perplexities)\n",
    "    return np.mean(perplexities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_rnn_df = pd.DataFrame(columns=['Corpus', 'train_perplexity', 'test_perplexity'])\n",
    "\n",
    "perplexity_rnn_df = pd.DataFrame({\n",
    "    'Corpus': pd.Series(dtype='str'),  # Or 'object'\n",
    "    'train_perplexity': pd.Series(dtype='float'),\n",
    "    'test_perplexity': pd.Series(dtype='float')\n",
    "})\n",
    "perplexity_rnn_df = pd.DataFrame([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity for Corpus - Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Load model weights\n",
    "# state_dict = torch.load(\"Models/2021102040_rnn_corpus1.pt\")\n",
    "# # expected_vocab_size = state_dict['embedding.weight'].shape[0]\n",
    "# # Initialize model\n",
    "# model_rnn_1 = VanillaRNN(vocab_size=len(train_vocab1), embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "# model_rnn_1.load_state_dict(state_dict)\n",
    "# model_rnn_1.to(device)\n",
    "# model_rnn_1.eval()\n",
    "\n",
    "# Compute perplexity\n",
    "print(\"\\nCalculating training perplexity...\")\n",
    "train_perplexity = evaluate_and_save_perplexity_rnn(model_rnn_1, train_indices1, 'corpus1', 'train', device)\n",
    "\n",
    "print(\"Calculating test perplexity...\")\n",
    "test_perplexity = evaluate_and_save_perplexity_rnn(model_rnn_1, test_indices1, 'corpus1', 'test', device)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal Results for RNN (Corpus 1):\")\n",
    "print(f\"Training Perplexity: {train_perplexity:.2f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "\n",
    "# Store results in DataFrame\n",
    "new_row = pd.DataFrame([{'Corpus': \"Pride and Prejudice\", 'train_perplexity': train_perplexity, 'test_perplexity': test_perplexity}])\n",
    "perplexity_rnn_df = pd.concat([perplexity_rnn_df, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity for Corpus - Ulysses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model_rnn_2 = VanillaRNN(vocab_size=len(train_vocab2), embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "# Load model weights\n",
    "state_dict = torch.load(\"Models/2021102040_rnn_corpus2.pt\")\n",
    "model_rnn_2.load_state_dict(state_dict)\n",
    "model_rnn_2.to(device)\n",
    "model_rnn_2.eval()\n",
    "\n",
    "# Compute perplexity\n",
    "print(\"\\nCalculating training perplexity...\")\n",
    "train_perplexity = evaluate_and_save_perplexity_rnn(model_rnn_2, train_indices1, 'corpus2', 'train', device)\n",
    "\n",
    "print(\"Calculating test perplexity...\")\n",
    "test_perplexity = evaluate_and_save_perplexity_rnn(model_rnn_2, test_indices1, 'corpus2', 'test', device)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal Results for RNN (Corpus 2):\")\n",
    "print(f\"Training Perplexity: {train_perplexity:.2f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "\n",
    "# Store results in DataFrame\n",
    "new_row = pd.DataFrame([{'Corpus': \"Ulysses\", 'train_perplexity': train_perplexity, 'test_perplexity': test_perplexity}])\n",
    "perplexity_rnn_df = pd.concat([perplexity_rnn_df, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Next word predction for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentence_to_tensor(sentence, word_to_idx, context_size, device='cpu'):\n",
    "    \"\"\"\n",
    "    Convert a sentence into a tensor format suitable for the RNN model.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): Input sentence.\n",
    "        word_to_idx (dict): Mapping from words to indices.\n",
    "        context_size (int): Number of words used as context.\n",
    "        device (str): Device to place the tensor ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Context tensor of shape (1, context_size).\n",
    "    \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    words = re.sub(r\"[^a-zA-Z\\s]\", \"\", sentence).split()\n",
    "    \n",
    "    if len(words) < context_size:\n",
    "        raise ValueError(f\"Input sentence must have at least {context_size} words\")\n",
    "    \n",
    "    # Extract the last `context_size` words\n",
    "    context_words = words[-context_size:]\n",
    "    \n",
    "    # Convert words to indices\n",
    "    context_indices = [word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in context_words]\n",
    "    \n",
    "    # Convert to tensor (1, context_size)\n",
    "    context_tensor = torch.tensor([context_indices], dtype=torch.long).to(device)\n",
    "    \n",
    "    return context_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sentence: I Love cat\n",
      "Top 5 predicted next words:\n",
      "him: 0.0756\n",
      "a: 0.0637\n",
      "in: 0.0458\n",
      "with: 0.0348\n",
      "to: 0.0307\n"
     ]
    }
   ],
   "source": [
    "# Example input sentence\n",
    "custom_sentence = \"I Love cat\"\n",
    "\n",
    "# Convert sentence to tensor\n",
    "context_tensor = sentence_to_tensor(custom_sentence, word_to_idx=train_vocab2, context_size=3, device='cpu')\n",
    "\n",
    "# Predict next word using your RNN model\n",
    "predictions = model_rnn_2.predict_next_word(context_tensor, idx_to_word2, top_k=5)\n",
    "\n",
    "# Print predictions\n",
    "print_predictions(custom_sentence, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Models/2021102040_rnn_corpus1.pth\"\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "# Extract saved components\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]\n",
    "idx_to_word = checkpoint[\"idx_to_word\"]\n",
    "hyperparams = checkpoint[\"hyperparams\"]\n",
    "embedding_dim = hyperparams[\"embedding_dim\"]\n",
    "hidden_dim = hyperparams[\"hidden_dim\"]\n",
    "vocab_size = hyperparams[\"vocab_size\"]\n",
    "model_rnn_1 = VanillaRNN(vocab_size, embedding_dim, hidden_dim)\n",
    "\n",
    "model_rnn_1.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "model_rnn_1.eval()\n",
    "\n",
    "print(\" Model successfully loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sentence: I Love cat since\n",
      "Top 5 predicted next words:\n",
      "we: 0.1124\n",
      "the: 0.0970\n",
      "her: 0.0689\n",
      "having: 0.0626\n",
      "any: 0.0607\n"
     ]
    }
   ],
   "source": [
    "# Example input sentence\n",
    "custom_sentence = \"I Love cat since\"\n",
    "\n",
    "# Convert sentence to tensor\n",
    "context_tensor = sentence_to_tensor(custom_sentence, word_to_idx=word_to_idx, context_size=4, device='cpu')\n",
    "\n",
    "# Predict next word using your RNN model\n",
    "predictions = model_rnn_1.predict_next_word(context_tensor, idx_to_word, top_k=5)\n",
    "\n",
    "# Print predictions\n",
    "print_predictions(custom_sentence, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Models/2021102040_rnn_corpus2.pth\"\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "# Extract saved components\n",
    "word_to_idx = checkpoint[\"word_to_idx\"]\n",
    "idx_to_word = checkpoint[\"idx_to_word\"]\n",
    "hyperparams = checkpoint[\"hyperparams\"]\n",
    "embedding_dim = hyperparams[\"embedding_dim\"]\n",
    "hidden_dim = hyperparams[\"hidden_dim\"]\n",
    "vocab_size = hyperparams[\"vocab_size\"]\n",
    "model_rnn_2 = VanillaRNN(vocab_size, embedding_dim, hidden_dim)\n",
    "\n",
    "model_rnn_2.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "model_rnn_2.eval()\n",
    "\n",
    "print(\" Model successfully loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sentence: I Love cat since\n",
      "Top 5 predicted next words:\n",
      "your: 0.0855\n",
      "the: 0.0751\n",
      "jacquard: 0.0445\n",
      "it: 0.0272\n",
      "a: 0.0256\n"
     ]
    }
   ],
   "source": [
    "# Example input sentence\n",
    "custom_sentence = \"I Love cat since\"\n",
    "\n",
    "# Convert sentence to tensor\n",
    "context_tensor = sentence_to_tensor(custom_sentence, word_to_idx=word_to_idx, context_size=4, device='cpu')\n",
    "\n",
    "# Predict next word using your RNN model\n",
    "predictions = model_rnn_2.predict_next_word(context_tensor, idx_to_word, top_k=5)\n",
    "\n",
    "# Print predictions\n",
    "print_predictions(custom_sentence, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
